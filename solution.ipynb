{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SOLUTION\n",
    "\n",
    "Это первый ноутбук\n",
    "Здесь препроцессинг данных и прогон нескольких plug and play моделек"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "seed = 69\n",
    "np.random.seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:24.806499600Z",
     "start_time": "2024-04-29T16:31:23.784366900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PREPROCESSING\n",
    "\n",
    "читаем данные\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   rank  query_id  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n0     0        10        1.0        0.0        1.0        3.0        3.0   \n1     1        10        3.0        0.0        3.0        0.0        3.0   \n2     0        10        3.0        0.0        2.0        0.0        3.0   \n3     1        10        3.0        0.0        3.0        0.0        3.0   \n4     2        10        3.0        0.0        3.0        1.0        3.0   \n\n   feature_5  feature_6  feature_7  ...  feature_134  feature_135  \\\n0   0.333333        0.0   0.333333  ...          0.0     0.000000   \n1   1.000000        0.0   1.000000  ...          0.0     0.000000   \n2   1.000000        0.0   0.666667  ...          0.0     0.000000   \n3   1.000000        0.0   1.000000  ...          0.0     0.000000   \n4   1.000000        0.0   1.000000  ...        273.0    79.670665   \n\n   feature_136  feature_137  feature_138  feature_139  feature_140  \\\n0     0.454545     0.890238     8.655534     1.000000     0.077778   \n1     0.000000     0.773976    23.130514     0.000000     0.027826   \n2     0.000000     0.918308    13.351339     0.000000     0.014925   \n3     0.000000     0.975355    18.240926     0.000000     0.053140   \n4     0.200000     0.990119    31.786048     0.333333     0.046512   \n\n   feature_141  feature_142  feature_143  \n0     0.002222          1.0     0.333333  \n1     0.000430         44.0    14.666667  \n2     0.000104         22.0     7.333333  \n3     0.000255          8.0     2.666667  \n4     0.000307         24.0     8.000000  \n\n[5 rows x 146 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank</th>\n      <th>query_id</th>\n      <th>feature_0</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>...</th>\n      <th>feature_134</th>\n      <th>feature_135</th>\n      <th>feature_136</th>\n      <th>feature_137</th>\n      <th>feature_138</th>\n      <th>feature_139</th>\n      <th>feature_140</th>\n      <th>feature_141</th>\n      <th>feature_142</th>\n      <th>feature_143</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>10</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.454545</td>\n      <td>0.890238</td>\n      <td>8.655534</td>\n      <td>1.000000</td>\n      <td>0.077778</td>\n      <td>0.002222</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.773976</td>\n      <td>23.130514</td>\n      <td>0.000000</td>\n      <td>0.027826</td>\n      <td>0.000430</td>\n      <td>44.0</td>\n      <td>14.666667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>10</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.918308</td>\n      <td>13.351339</td>\n      <td>0.000000</td>\n      <td>0.014925</td>\n      <td>0.000104</td>\n      <td>22.0</td>\n      <td>7.333333</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>10</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.975355</td>\n      <td>18.240926</td>\n      <td>0.000000</td>\n      <td>0.053140</td>\n      <td>0.000255</td>\n      <td>8.0</td>\n      <td>2.666667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>10</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>273.0</td>\n      <td>79.670665</td>\n      <td>0.200000</td>\n      <td>0.990119</td>\n      <td>31.786048</td>\n      <td>0.333333</td>\n      <td>0.046512</td>\n      <td>0.000307</td>\n      <td>24.0</td>\n      <td>8.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 146 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('data/intern_task.csv')\n",
    "data_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:26.351284300Z",
     "start_time": "2024-04-29T16:31:24.789483500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Начнем с проверки на пропуски данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "preproc = data_df.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:26.357979400Z",
     "start_time": "2024-04-29T16:31:26.340276800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список столбцов, где есть пропуск []\n"
     ]
    },
    {
     "data": {
      "text/plain": "rank           0\nquery_id       0\nfeature_0      0\nfeature_1      0\nfeature_2      0\n              ..\nfeature_139    0\nfeature_140    0\nfeature_141    0\nfeature_142    0\nfeature_143    0\nLength: 146, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Список столбцов, где есть пропуск {preproc.columns[preproc.isnull().any()].tolist()}\")\n",
    "preproc.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:26.949805200Z",
     "start_time": "2024-04-29T16:31:26.651025300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "пропусков нет. супер!\n",
    "\n",
    "Посмотрим что у нас есть в данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                count          mean          std   min          25%  \\\nrank         235258.0      0.677869     0.830033   0.0     0.000000   \nquery_id     235258.0  14828.413401  8193.945170  10.0  8215.000000   \nfeature_0    235258.0      1.911960     1.237374   0.0     1.000000   \nfeature_1    235258.0      0.206233     0.579089   0.0     0.000000   \nfeature_2    235258.0      1.189847     1.037233   0.0     0.000000   \n...               ...           ...          ...   ...          ...   \nfeature_139  235258.0      0.281747     0.392089   0.0     0.000000   \nfeature_140  235258.0      0.027033     0.033351   0.0     0.006703   \nfeature_141  235258.0      0.000269     0.002088   0.0     0.000000   \nfeature_142  235258.0     22.457910    63.708018   0.0     4.000000   \nfeature_143  235258.0      9.560379    14.347378   0.0     2.000000   \n\n                      50%           75%           max  \nrank             0.000000      1.000000      4.000000  \nquery_id     14935.000000  21580.000000  29995.000000  \nfeature_0        2.000000      3.000000     31.000000  \nfeature_1        0.000000      0.000000     18.000000  \nfeature_2        1.000000      2.000000     27.000000  \n...                   ...           ...           ...  \nfeature_139      0.000000      0.500000      1.000000  \nfeature_140      0.017761      0.034954      0.711261  \nfeature_141      0.000008      0.000109      0.250000  \nfeature_142     12.000000     28.000000  15074.000000  \nfeature_143      5.500000     12.000000   1552.000000  \n\n[146 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>rank</th>\n      <td>235258.0</td>\n      <td>0.677869</td>\n      <td>0.830033</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>query_id</th>\n      <td>235258.0</td>\n      <td>14828.413401</td>\n      <td>8193.945170</td>\n      <td>10.0</td>\n      <td>8215.000000</td>\n      <td>14935.000000</td>\n      <td>21580.000000</td>\n      <td>29995.000000</td>\n    </tr>\n    <tr>\n      <th>feature_0</th>\n      <td>235258.0</td>\n      <td>1.911960</td>\n      <td>1.237374</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>feature_1</th>\n      <td>235258.0</td>\n      <td>0.206233</td>\n      <td>0.579089</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>18.000000</td>\n    </tr>\n    <tr>\n      <th>feature_2</th>\n      <td>235258.0</td>\n      <td>1.189847</td>\n      <td>1.037233</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>27.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>feature_139</th>\n      <td>235258.0</td>\n      <td>0.281747</td>\n      <td>0.392089</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>feature_140</th>\n      <td>235258.0</td>\n      <td>0.027033</td>\n      <td>0.033351</td>\n      <td>0.0</td>\n      <td>0.006703</td>\n      <td>0.017761</td>\n      <td>0.034954</td>\n      <td>0.711261</td>\n    </tr>\n    <tr>\n      <th>feature_141</th>\n      <td>235258.0</td>\n      <td>0.000269</td>\n      <td>0.002088</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000008</td>\n      <td>0.000109</td>\n      <td>0.250000</td>\n    </tr>\n    <tr>\n      <th>feature_142</th>\n      <td>235258.0</td>\n      <td>22.457910</td>\n      <td>63.708018</td>\n      <td>0.0</td>\n      <td>4.000000</td>\n      <td>12.000000</td>\n      <td>28.000000</td>\n      <td>15074.000000</td>\n    </tr>\n    <tr>\n      <th>feature_143</th>\n      <td>235258.0</td>\n      <td>9.560379</td>\n      <td>14.347378</td>\n      <td>0.0</td>\n      <td>2.000000</td>\n      <td>5.500000</td>\n      <td>12.000000</td>\n      <td>1552.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>146 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.describe().transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:28.879139400Z",
     "start_time": "2024-04-29T16:31:28.123585900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Потыкавшись по этой табличке можно сразу заметить, что фичи 100, 72, 65, 64 не несут никакого смысла, потому что они все равны какому-то одному значению для всех записей (std=0), откинем их"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def drop(df, to_drop):\n",
    "    for col in to_drop:\n",
    "        df = df.drop(columns=col)\n",
    "    return df\n",
    "\n",
    "\n",
    "preproc = drop(preproc, ['feature_64', 'feature_65', 'feature_72', 'feature_100'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:29.172665900Z",
     "start_time": "2024-04-29T16:31:29.158762300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Переведём в явный int"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Столбцы с целыми числами, хранящимися в float:\n",
      "['rank', 'query_id', 'feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_95', 'feature_96', 'feature_97', 'feature_98', 'feature_99', 'feature_125', 'feature_126', 'feature_127', 'feature_128', 'feature_129', 'feature_130', 'feature_131', 'feature_132', 'feature_133', 'feature_134', 'feature_142']\n"
     ]
    },
    {
     "data": {
      "text/plain": "   rank  query_id  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n0     0        10          1          0          1          3          3   \n1     1        10          3          0          3          0          3   \n2     0        10          3          0          2          0          3   \n3     1        10          3          0          3          0          3   \n4     2        10          3          0          3          1          3   \n\n   feature_5  feature_6  feature_7  ...  feature_134  feature_135  \\\n0   0.333333        0.0   0.333333  ...            0     0.000000   \n1   1.000000        0.0   1.000000  ...            0     0.000000   \n2   1.000000        0.0   0.666667  ...            0     0.000000   \n3   1.000000        0.0   1.000000  ...            0     0.000000   \n4   1.000000        0.0   1.000000  ...          273    79.670665   \n\n   feature_136  feature_137  feature_138  feature_139  feature_140  \\\n0     0.454545     0.890238     8.655534     1.000000     0.077778   \n1     0.000000     0.773976    23.130514     0.000000     0.027826   \n2     0.000000     0.918308    13.351339     0.000000     0.014925   \n3     0.000000     0.975355    18.240926     0.000000     0.053140   \n4     0.200000     0.990119    31.786048     0.333333     0.046512   \n\n   feature_141  feature_142  feature_143  \n0     0.002222            1     0.333333  \n1     0.000430           44    14.666667  \n2     0.000104           22     7.333333  \n3     0.000255            8     2.666667  \n4     0.000307           24     8.000000  \n\n[5 rows x 142 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank</th>\n      <th>query_id</th>\n      <th>feature_0</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>...</th>\n      <th>feature_134</th>\n      <th>feature_135</th>\n      <th>feature_136</th>\n      <th>feature_137</th>\n      <th>feature_138</th>\n      <th>feature_139</th>\n      <th>feature_140</th>\n      <th>feature_141</th>\n      <th>feature_142</th>\n      <th>feature_143</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>10</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.454545</td>\n      <td>0.890238</td>\n      <td>8.655534</td>\n      <td>1.000000</td>\n      <td>0.077778</td>\n      <td>0.002222</td>\n      <td>1</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.773976</td>\n      <td>23.130514</td>\n      <td>0.000000</td>\n      <td>0.027826</td>\n      <td>0.000430</td>\n      <td>44</td>\n      <td>14.666667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.918308</td>\n      <td>13.351339</td>\n      <td>0.000000</td>\n      <td>0.014925</td>\n      <td>0.000104</td>\n      <td>22</td>\n      <td>7.333333</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.975355</td>\n      <td>18.240926</td>\n      <td>0.000000</td>\n      <td>0.053140</td>\n      <td>0.000255</td>\n      <td>8</td>\n      <td>2.666667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>273</td>\n      <td>79.670665</td>\n      <td>0.200000</td>\n      <td>0.990119</td>\n      <td>31.786048</td>\n      <td>0.333333</td>\n      <td>0.046512</td>\n      <td>0.000307</td>\n      <td>24</td>\n      <td>8.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 142 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer_columns = [col for col in preproc.columns if preproc[col].dtype == 'int64']\n",
    "for column in preproc.columns:\n",
    "    if column not in integer_columns:\n",
    "        if all(value.is_integer() for value in preproc[column]):\n",
    "            integer_columns.append(column)\n",
    "\n",
    "print(\"Столбцы с целыми числами, хранящимися в float:\")\n",
    "print(integer_columns)\n",
    "\n",
    "for col in integer_columns:\n",
    "    preproc[col] = preproc[col].astype(int)\n",
    "\n",
    "preproc.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:30.844493Z",
     "start_time": "2024-04-29T16:31:30.137493Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сделаем похожий фокус для столбцов с только 2 значеними и превратим их в булы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "rank               5\nquery_id        2000\nfeature_0         16\nfeature_1         10\nfeature_2         15\n               ...  \nfeature_139       29\nfeature_140    41864\nfeature_141     4703\nfeature_142      529\nfeature_143     1431\nLength: 142, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_columns = []\n",
    "\n",
    "for col in preproc.columns:\n",
    "    unique_values = preproc[col].unique()\n",
    "    if len(unique_values) == 2:\n",
    "        preproc[col] = preproc[col].map({unique_values[0]: False, unique_values[1]: True})\n",
    "        bool_columns.append(col)\n",
    "\n",
    "preproc.nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:31.870153500Z",
     "start_time": "2024-04-29T16:31:31.141801200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "['feature_95', 'feature_96', 'feature_97', 'feature_98', 'feature_99']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:31.878876200Z",
     "start_time": "2024-04-29T16:31:31.876166100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Пробежавшись глазами по данным я заметил, что некоторые столбцы имеют очень похожие значения\n",
    "Но прям идентичных стобцов нет\n",
    "Посмотрим как они коррелируют"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                 rank  query_id  feature_0  feature_1  feature_2  feature_3  \\\nrank         1.000000  0.074057  -0.034239   0.097110   0.177743   0.120893   \nquery_id     0.074057  1.000000  -0.040320  -0.019186  -0.004201   0.020878   \nfeature_0   -0.034239 -0.040320   1.000000   0.131044   0.560199   0.155114   \nfeature_1    0.097110 -0.019186   0.131044   1.000000   0.208730   0.196483   \nfeature_2    0.177743 -0.004201   0.560199   0.208730   1.000000   0.306295   \n...               ...       ...        ...        ...        ...        ...   \nfeature_139  0.149626  0.049949  -0.111323   0.134350   0.111337   0.833796   \nfeature_140  0.155181  0.034563  -0.047251   0.105877   0.189865   0.225540   \nfeature_141  0.001207 -0.005864   0.026149   0.016457   0.037717   0.036037   \nfeature_142  0.017734  0.001791   0.309202   0.114352   0.235129   0.084797   \nfeature_143  0.087033  0.011541   0.162987   0.182067   0.224031   0.138388   \n\n             feature_4  feature_5  feature_6  feature_7  ...  feature_134  \\\nrank         -0.029628   0.078850   0.109373   0.231477  ...    -0.002400   \nquery_id     -0.036808  -0.005223  -0.007782   0.032868  ...    -0.005803   \nfeature_0     0.979494   0.590972   0.008262   0.176838  ...    -0.020799   \nfeature_1     0.142909   0.119076   0.890659   0.159313  ...    -0.007154   \nfeature_2     0.538310   0.482131   0.124211   0.768004  ...    -0.020478   \n...                ...        ...        ...        ...  ...          ...   \nfeature_139  -0.067245   0.139908   0.195519   0.287774  ...    -0.009599   \nfeature_140  -0.013788   0.191179   0.149277   0.355177  ...    -0.010228   \nfeature_141   0.029016  -0.003988   0.003916   0.007805  ...    -0.002304   \nfeature_142   0.305479   0.143931   0.076314   0.095519  ...    -0.006998   \nfeature_143   0.143346   0.298241   0.209711   0.284985  ...    -0.012782   \n\n             feature_135  feature_136  feature_137  feature_138  feature_139  \\\nrank           -0.000130     0.135449     0.098959     0.121585     0.149626   \nquery_id        0.001679     0.026565     0.000980     0.006226     0.049949   \nfeature_0       0.000721     0.083786     0.437207     0.335744    -0.111323   \nfeature_1      -0.001405     0.178257     0.105447     0.134541     0.134350   \nfeature_2       0.000422     0.240712     0.435177     0.621490     0.111337   \n...                  ...          ...          ...          ...          ...   \nfeature_139    -0.000954     0.843068     0.179221     0.098203     1.000000   \nfeature_140     0.000567     0.285388     0.216457     0.189261     0.336723   \nfeature_141    -0.000052     0.037421    -0.020480     0.044194     0.006884   \nfeature_142    -0.000398     0.075562     0.086268     0.307781     0.020168   \nfeature_143    -0.000301     0.150076     0.240151     0.244936     0.145930   \n\n             feature_140  feature_141  feature_142  feature_143  \nrank            0.155181     0.001207     0.017734     0.087033  \nquery_id        0.034563    -0.005864     0.001791     0.011541  \nfeature_0      -0.047251     0.026149     0.309202     0.162987  \nfeature_1       0.105877     0.016457     0.114352     0.182067  \nfeature_2       0.189865     0.037717     0.235129     0.224031  \n...                  ...          ...          ...          ...  \nfeature_139     0.336723     0.006884     0.020168     0.145930  \nfeature_140     1.000000     0.169442     0.092988     0.262832  \nfeature_141     0.169442     1.000000     0.072902     0.097090  \nfeature_142     0.092988     0.072902     1.000000     0.570354  \nfeature_143     0.262832     0.097090     0.570354     1.000000  \n\n[142 rows x 142 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank</th>\n      <th>query_id</th>\n      <th>feature_0</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>...</th>\n      <th>feature_134</th>\n      <th>feature_135</th>\n      <th>feature_136</th>\n      <th>feature_137</th>\n      <th>feature_138</th>\n      <th>feature_139</th>\n      <th>feature_140</th>\n      <th>feature_141</th>\n      <th>feature_142</th>\n      <th>feature_143</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>rank</th>\n      <td>1.000000</td>\n      <td>0.074057</td>\n      <td>-0.034239</td>\n      <td>0.097110</td>\n      <td>0.177743</td>\n      <td>0.120893</td>\n      <td>-0.029628</td>\n      <td>0.078850</td>\n      <td>0.109373</td>\n      <td>0.231477</td>\n      <td>...</td>\n      <td>-0.002400</td>\n      <td>-0.000130</td>\n      <td>0.135449</td>\n      <td>0.098959</td>\n      <td>0.121585</td>\n      <td>0.149626</td>\n      <td>0.155181</td>\n      <td>0.001207</td>\n      <td>0.017734</td>\n      <td>0.087033</td>\n    </tr>\n    <tr>\n      <th>query_id</th>\n      <td>0.074057</td>\n      <td>1.000000</td>\n      <td>-0.040320</td>\n      <td>-0.019186</td>\n      <td>-0.004201</td>\n      <td>0.020878</td>\n      <td>-0.036808</td>\n      <td>-0.005223</td>\n      <td>-0.007782</td>\n      <td>0.032868</td>\n      <td>...</td>\n      <td>-0.005803</td>\n      <td>0.001679</td>\n      <td>0.026565</td>\n      <td>0.000980</td>\n      <td>0.006226</td>\n      <td>0.049949</td>\n      <td>0.034563</td>\n      <td>-0.005864</td>\n      <td>0.001791</td>\n      <td>0.011541</td>\n    </tr>\n    <tr>\n      <th>feature_0</th>\n      <td>-0.034239</td>\n      <td>-0.040320</td>\n      <td>1.000000</td>\n      <td>0.131044</td>\n      <td>0.560199</td>\n      <td>0.155114</td>\n      <td>0.979494</td>\n      <td>0.590972</td>\n      <td>0.008262</td>\n      <td>0.176838</td>\n      <td>...</td>\n      <td>-0.020799</td>\n      <td>0.000721</td>\n      <td>0.083786</td>\n      <td>0.437207</td>\n      <td>0.335744</td>\n      <td>-0.111323</td>\n      <td>-0.047251</td>\n      <td>0.026149</td>\n      <td>0.309202</td>\n      <td>0.162987</td>\n    </tr>\n    <tr>\n      <th>feature_1</th>\n      <td>0.097110</td>\n      <td>-0.019186</td>\n      <td>0.131044</td>\n      <td>1.000000</td>\n      <td>0.208730</td>\n      <td>0.196483</td>\n      <td>0.142909</td>\n      <td>0.119076</td>\n      <td>0.890659</td>\n      <td>0.159313</td>\n      <td>...</td>\n      <td>-0.007154</td>\n      <td>-0.001405</td>\n      <td>0.178257</td>\n      <td>0.105447</td>\n      <td>0.134541</td>\n      <td>0.134350</td>\n      <td>0.105877</td>\n      <td>0.016457</td>\n      <td>0.114352</td>\n      <td>0.182067</td>\n    </tr>\n    <tr>\n      <th>feature_2</th>\n      <td>0.177743</td>\n      <td>-0.004201</td>\n      <td>0.560199</td>\n      <td>0.208730</td>\n      <td>1.000000</td>\n      <td>0.306295</td>\n      <td>0.538310</td>\n      <td>0.482131</td>\n      <td>0.124211</td>\n      <td>0.768004</td>\n      <td>...</td>\n      <td>-0.020478</td>\n      <td>0.000422</td>\n      <td>0.240712</td>\n      <td>0.435177</td>\n      <td>0.621490</td>\n      <td>0.111337</td>\n      <td>0.189865</td>\n      <td>0.037717</td>\n      <td>0.235129</td>\n      <td>0.224031</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>feature_139</th>\n      <td>0.149626</td>\n      <td>0.049949</td>\n      <td>-0.111323</td>\n      <td>0.134350</td>\n      <td>0.111337</td>\n      <td>0.833796</td>\n      <td>-0.067245</td>\n      <td>0.139908</td>\n      <td>0.195519</td>\n      <td>0.287774</td>\n      <td>...</td>\n      <td>-0.009599</td>\n      <td>-0.000954</td>\n      <td>0.843068</td>\n      <td>0.179221</td>\n      <td>0.098203</td>\n      <td>1.000000</td>\n      <td>0.336723</td>\n      <td>0.006884</td>\n      <td>0.020168</td>\n      <td>0.145930</td>\n    </tr>\n    <tr>\n      <th>feature_140</th>\n      <td>0.155181</td>\n      <td>0.034563</td>\n      <td>-0.047251</td>\n      <td>0.105877</td>\n      <td>0.189865</td>\n      <td>0.225540</td>\n      <td>-0.013788</td>\n      <td>0.191179</td>\n      <td>0.149277</td>\n      <td>0.355177</td>\n      <td>...</td>\n      <td>-0.010228</td>\n      <td>0.000567</td>\n      <td>0.285388</td>\n      <td>0.216457</td>\n      <td>0.189261</td>\n      <td>0.336723</td>\n      <td>1.000000</td>\n      <td>0.169442</td>\n      <td>0.092988</td>\n      <td>0.262832</td>\n    </tr>\n    <tr>\n      <th>feature_141</th>\n      <td>0.001207</td>\n      <td>-0.005864</td>\n      <td>0.026149</td>\n      <td>0.016457</td>\n      <td>0.037717</td>\n      <td>0.036037</td>\n      <td>0.029016</td>\n      <td>-0.003988</td>\n      <td>0.003916</td>\n      <td>0.007805</td>\n      <td>...</td>\n      <td>-0.002304</td>\n      <td>-0.000052</td>\n      <td>0.037421</td>\n      <td>-0.020480</td>\n      <td>0.044194</td>\n      <td>0.006884</td>\n      <td>0.169442</td>\n      <td>1.000000</td>\n      <td>0.072902</td>\n      <td>0.097090</td>\n    </tr>\n    <tr>\n      <th>feature_142</th>\n      <td>0.017734</td>\n      <td>0.001791</td>\n      <td>0.309202</td>\n      <td>0.114352</td>\n      <td>0.235129</td>\n      <td>0.084797</td>\n      <td>0.305479</td>\n      <td>0.143931</td>\n      <td>0.076314</td>\n      <td>0.095519</td>\n      <td>...</td>\n      <td>-0.006998</td>\n      <td>-0.000398</td>\n      <td>0.075562</td>\n      <td>0.086268</td>\n      <td>0.307781</td>\n      <td>0.020168</td>\n      <td>0.092988</td>\n      <td>0.072902</td>\n      <td>1.000000</td>\n      <td>0.570354</td>\n    </tr>\n    <tr>\n      <th>feature_143</th>\n      <td>0.087033</td>\n      <td>0.011541</td>\n      <td>0.162987</td>\n      <td>0.182067</td>\n      <td>0.224031</td>\n      <td>0.138388</td>\n      <td>0.143346</td>\n      <td>0.298241</td>\n      <td>0.209711</td>\n      <td>0.284985</td>\n      <td>...</td>\n      <td>-0.012782</td>\n      <td>-0.000301</td>\n      <td>0.150076</td>\n      <td>0.240151</td>\n      <td>0.244936</td>\n      <td>0.145930</td>\n      <td>0.262832</td>\n      <td>0.097090</td>\n      <td>0.570354</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>142 rows × 142 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.corr()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:38.814343300Z",
     "start_time": "2024-04-29T16:31:33.350913300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Есть парочка столбцов у которых очень высокая корреляция, например id запроса и фичи 20, 35, 8, кажется, что они линейно зависимы и может быть это одно и то же значение только умноженные на разные константы\n",
    "Попробую отскейлить, может быть чем-то поможет"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                 rank  query_id  feature_0  feature_1  feature_2  feature_3  \\\nrank         1.000000  0.074057  -0.034239   0.097110   0.177743   0.120893   \nquery_id     0.074057  1.000000  -0.040320  -0.019186  -0.004201   0.020878   \nfeature_0   -0.034239 -0.040320   1.000000   0.131044   0.560199   0.155114   \nfeature_1    0.097110 -0.019186   0.131044   1.000000   0.208730   0.196483   \nfeature_2    0.177743 -0.004201   0.560199   0.208730   1.000000   0.306295   \n...               ...       ...        ...        ...        ...        ...   \nfeature_139  0.149626  0.049949  -0.111323   0.134350   0.111337   0.833796   \nfeature_140  0.155181  0.034563  -0.047251   0.105877   0.189865   0.225540   \nfeature_141  0.001207 -0.005864   0.026149   0.016457   0.037717   0.036037   \nfeature_142  0.017734  0.001791   0.309202   0.114352   0.235129   0.084797   \nfeature_143  0.087033  0.011541   0.162987   0.182067   0.224031   0.138388   \n\n             feature_4  feature_5  feature_6  feature_7  ...  feature_134  \\\nrank         -0.029628   0.078850   0.109373   0.231477  ...    -0.002400   \nquery_id     -0.036808  -0.005223  -0.007782   0.032868  ...    -0.005803   \nfeature_0     0.979494   0.590972   0.008262   0.176838  ...    -0.020799   \nfeature_1     0.142909   0.119076   0.890659   0.159313  ...    -0.007154   \nfeature_2     0.538310   0.482131   0.124211   0.768004  ...    -0.020478   \n...                ...        ...        ...        ...  ...          ...   \nfeature_139  -0.067245   0.139908   0.195519   0.287774  ...    -0.009599   \nfeature_140  -0.013788   0.191179   0.149277   0.355177  ...    -0.010228   \nfeature_141   0.029016  -0.003988   0.003916   0.007805  ...    -0.002304   \nfeature_142   0.305479   0.143931   0.076314   0.095519  ...    -0.006998   \nfeature_143   0.143346   0.298241   0.209711   0.284985  ...    -0.012782   \n\n             feature_135  feature_136  feature_137  feature_138  feature_139  \\\nrank           -0.000130     0.135449     0.098959     0.121585     0.149626   \nquery_id        0.001679     0.026565     0.000980     0.006226     0.049949   \nfeature_0       0.000721     0.083786     0.437207     0.335744    -0.111323   \nfeature_1      -0.001405     0.178257     0.105447     0.134541     0.134350   \nfeature_2       0.000422     0.240712     0.435177     0.621490     0.111337   \n...                  ...          ...          ...          ...          ...   \nfeature_139    -0.000954     0.843068     0.179221     0.098203     1.000000   \nfeature_140     0.000567     0.285388     0.216457     0.189261     0.336723   \nfeature_141    -0.000052     0.037421    -0.020480     0.044194     0.006884   \nfeature_142    -0.000398     0.075562     0.086268     0.307781     0.020168   \nfeature_143    -0.000301     0.150076     0.240151     0.244936     0.145930   \n\n             feature_140  feature_141  feature_142  feature_143  \nrank            0.155181     0.001207     0.017734     0.087033  \nquery_id        0.034563    -0.005864     0.001791     0.011541  \nfeature_0      -0.047251     0.026149     0.309202     0.162987  \nfeature_1       0.105877     0.016457     0.114352     0.182067  \nfeature_2       0.189865     0.037717     0.235129     0.224031  \n...                  ...          ...          ...          ...  \nfeature_139     0.336723     0.006884     0.020168     0.145930  \nfeature_140     1.000000     0.169442     0.092988     0.262832  \nfeature_141     0.169442     1.000000     0.072902     0.097090  \nfeature_142     0.092988     0.072902     1.000000     0.570354  \nfeature_143     0.262832     0.097090     0.570354     1.000000  \n\n[142 rows x 142 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank</th>\n      <th>query_id</th>\n      <th>feature_0</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>...</th>\n      <th>feature_134</th>\n      <th>feature_135</th>\n      <th>feature_136</th>\n      <th>feature_137</th>\n      <th>feature_138</th>\n      <th>feature_139</th>\n      <th>feature_140</th>\n      <th>feature_141</th>\n      <th>feature_142</th>\n      <th>feature_143</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>rank</th>\n      <td>1.000000</td>\n      <td>0.074057</td>\n      <td>-0.034239</td>\n      <td>0.097110</td>\n      <td>0.177743</td>\n      <td>0.120893</td>\n      <td>-0.029628</td>\n      <td>0.078850</td>\n      <td>0.109373</td>\n      <td>0.231477</td>\n      <td>...</td>\n      <td>-0.002400</td>\n      <td>-0.000130</td>\n      <td>0.135449</td>\n      <td>0.098959</td>\n      <td>0.121585</td>\n      <td>0.149626</td>\n      <td>0.155181</td>\n      <td>0.001207</td>\n      <td>0.017734</td>\n      <td>0.087033</td>\n    </tr>\n    <tr>\n      <th>query_id</th>\n      <td>0.074057</td>\n      <td>1.000000</td>\n      <td>-0.040320</td>\n      <td>-0.019186</td>\n      <td>-0.004201</td>\n      <td>0.020878</td>\n      <td>-0.036808</td>\n      <td>-0.005223</td>\n      <td>-0.007782</td>\n      <td>0.032868</td>\n      <td>...</td>\n      <td>-0.005803</td>\n      <td>0.001679</td>\n      <td>0.026565</td>\n      <td>0.000980</td>\n      <td>0.006226</td>\n      <td>0.049949</td>\n      <td>0.034563</td>\n      <td>-0.005864</td>\n      <td>0.001791</td>\n      <td>0.011541</td>\n    </tr>\n    <tr>\n      <th>feature_0</th>\n      <td>-0.034239</td>\n      <td>-0.040320</td>\n      <td>1.000000</td>\n      <td>0.131044</td>\n      <td>0.560199</td>\n      <td>0.155114</td>\n      <td>0.979494</td>\n      <td>0.590972</td>\n      <td>0.008262</td>\n      <td>0.176838</td>\n      <td>...</td>\n      <td>-0.020799</td>\n      <td>0.000721</td>\n      <td>0.083786</td>\n      <td>0.437207</td>\n      <td>0.335744</td>\n      <td>-0.111323</td>\n      <td>-0.047251</td>\n      <td>0.026149</td>\n      <td>0.309202</td>\n      <td>0.162987</td>\n    </tr>\n    <tr>\n      <th>feature_1</th>\n      <td>0.097110</td>\n      <td>-0.019186</td>\n      <td>0.131044</td>\n      <td>1.000000</td>\n      <td>0.208730</td>\n      <td>0.196483</td>\n      <td>0.142909</td>\n      <td>0.119076</td>\n      <td>0.890659</td>\n      <td>0.159313</td>\n      <td>...</td>\n      <td>-0.007154</td>\n      <td>-0.001405</td>\n      <td>0.178257</td>\n      <td>0.105447</td>\n      <td>0.134541</td>\n      <td>0.134350</td>\n      <td>0.105877</td>\n      <td>0.016457</td>\n      <td>0.114352</td>\n      <td>0.182067</td>\n    </tr>\n    <tr>\n      <th>feature_2</th>\n      <td>0.177743</td>\n      <td>-0.004201</td>\n      <td>0.560199</td>\n      <td>0.208730</td>\n      <td>1.000000</td>\n      <td>0.306295</td>\n      <td>0.538310</td>\n      <td>0.482131</td>\n      <td>0.124211</td>\n      <td>0.768004</td>\n      <td>...</td>\n      <td>-0.020478</td>\n      <td>0.000422</td>\n      <td>0.240712</td>\n      <td>0.435177</td>\n      <td>0.621490</td>\n      <td>0.111337</td>\n      <td>0.189865</td>\n      <td>0.037717</td>\n      <td>0.235129</td>\n      <td>0.224031</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>feature_139</th>\n      <td>0.149626</td>\n      <td>0.049949</td>\n      <td>-0.111323</td>\n      <td>0.134350</td>\n      <td>0.111337</td>\n      <td>0.833796</td>\n      <td>-0.067245</td>\n      <td>0.139908</td>\n      <td>0.195519</td>\n      <td>0.287774</td>\n      <td>...</td>\n      <td>-0.009599</td>\n      <td>-0.000954</td>\n      <td>0.843068</td>\n      <td>0.179221</td>\n      <td>0.098203</td>\n      <td>1.000000</td>\n      <td>0.336723</td>\n      <td>0.006884</td>\n      <td>0.020168</td>\n      <td>0.145930</td>\n    </tr>\n    <tr>\n      <th>feature_140</th>\n      <td>0.155181</td>\n      <td>0.034563</td>\n      <td>-0.047251</td>\n      <td>0.105877</td>\n      <td>0.189865</td>\n      <td>0.225540</td>\n      <td>-0.013788</td>\n      <td>0.191179</td>\n      <td>0.149277</td>\n      <td>0.355177</td>\n      <td>...</td>\n      <td>-0.010228</td>\n      <td>0.000567</td>\n      <td>0.285388</td>\n      <td>0.216457</td>\n      <td>0.189261</td>\n      <td>0.336723</td>\n      <td>1.000000</td>\n      <td>0.169442</td>\n      <td>0.092988</td>\n      <td>0.262832</td>\n    </tr>\n    <tr>\n      <th>feature_141</th>\n      <td>0.001207</td>\n      <td>-0.005864</td>\n      <td>0.026149</td>\n      <td>0.016457</td>\n      <td>0.037717</td>\n      <td>0.036037</td>\n      <td>0.029016</td>\n      <td>-0.003988</td>\n      <td>0.003916</td>\n      <td>0.007805</td>\n      <td>...</td>\n      <td>-0.002304</td>\n      <td>-0.000052</td>\n      <td>0.037421</td>\n      <td>-0.020480</td>\n      <td>0.044194</td>\n      <td>0.006884</td>\n      <td>0.169442</td>\n      <td>1.000000</td>\n      <td>0.072902</td>\n      <td>0.097090</td>\n    </tr>\n    <tr>\n      <th>feature_142</th>\n      <td>0.017734</td>\n      <td>0.001791</td>\n      <td>0.309202</td>\n      <td>0.114352</td>\n      <td>0.235129</td>\n      <td>0.084797</td>\n      <td>0.305479</td>\n      <td>0.143931</td>\n      <td>0.076314</td>\n      <td>0.095519</td>\n      <td>...</td>\n      <td>-0.006998</td>\n      <td>-0.000398</td>\n      <td>0.075562</td>\n      <td>0.086268</td>\n      <td>0.307781</td>\n      <td>0.020168</td>\n      <td>0.092988</td>\n      <td>0.072902</td>\n      <td>1.000000</td>\n      <td>0.570354</td>\n    </tr>\n    <tr>\n      <th>feature_143</th>\n      <td>0.087033</td>\n      <td>0.011541</td>\n      <td>0.162987</td>\n      <td>0.182067</td>\n      <td>0.224031</td>\n      <td>0.138388</td>\n      <td>0.143346</td>\n      <td>0.298241</td>\n      <td>0.209711</td>\n      <td>0.284985</td>\n      <td>...</td>\n      <td>-0.012782</td>\n      <td>-0.000301</td>\n      <td>0.150076</td>\n      <td>0.240151</td>\n      <td>0.244936</td>\n      <td>0.145930</td>\n      <td>0.262832</td>\n      <td>0.097090</td>\n      <td>0.570354</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>142 rows × 142 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "test_scale = preproc.copy()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "to_scale = [i for i in test_scale.columns.tolist() if i not in integer_columns and i not in bool_columns]\n",
    "\n",
    "test_scale[to_scale] = scaler.fit_transform(test_scale[to_scale])\n",
    "test_scale.corr()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:44.476091900Z",
     "start_time": "2024-04-29T16:31:38.815341800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Предоположение было верно, фичи 8, 20 и 35 буквально линейнозависимы (корреляция 1)\n",
    "\n",
    "также проверим автоматически другие фичи на линейнуюзависимость на всякий случай"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "['feature_8', 'feature_20', 'feature_35']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = test_scale.corr()\n",
    "cnt = []\n",
    "for i in cor.columns:\n",
    "    tmp = cor[i].value_counts()[1.0] + (-1.0 in cor[i].value_counts())\n",
    "    if tmp > 1:\n",
    "        cnt.append(i)\n",
    "cnt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:49.828768200Z",
     "start_time": "2024-04-29T16:31:44.451513300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "кроме 8, 20 и 35 ничего не нашлось\n",
    "тогда выбросим 20 и 35, чтобы не мешались"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "   rank  query_id  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n0     0        10          1          0          1          3          3   \n1     1        10          3          0          3          0          3   \n2     0        10          3          0          2          0          3   \n3     1        10          3          0          3          0          3   \n4     2        10          3          0          3          1          3   \n\n   feature_5  feature_6  feature_7  ...  feature_134  feature_135  \\\n0   0.333333        0.0   0.333333  ...            0     0.000000   \n1   1.000000        0.0   1.000000  ...            0     0.000000   \n2   1.000000        0.0   0.666667  ...            0     0.000000   \n3   1.000000        0.0   1.000000  ...            0     0.000000   \n4   1.000000        0.0   1.000000  ...          273    79.670665   \n\n   feature_136  feature_137  feature_138  feature_139  feature_140  \\\n0     0.454545     0.890238     8.655534     1.000000     0.077778   \n1     0.000000     0.773976    23.130514     0.000000     0.027826   \n2     0.000000     0.918308    13.351339     0.000000     0.014925   \n3     0.000000     0.975355    18.240926     0.000000     0.053140   \n4     0.200000     0.990119    31.786048     0.333333     0.046512   \n\n   feature_141  feature_142  feature_143  \n0     0.002222            1     0.333333  \n1     0.000430           44    14.666667  \n2     0.000104           22     7.333333  \n3     0.000255            8     2.666667  \n4     0.000307           24     8.000000  \n\n[5 rows x 140 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank</th>\n      <th>query_id</th>\n      <th>feature_0</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>...</th>\n      <th>feature_134</th>\n      <th>feature_135</th>\n      <th>feature_136</th>\n      <th>feature_137</th>\n      <th>feature_138</th>\n      <th>feature_139</th>\n      <th>feature_140</th>\n      <th>feature_141</th>\n      <th>feature_142</th>\n      <th>feature_143</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>10</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.454545</td>\n      <td>0.890238</td>\n      <td>8.655534</td>\n      <td>1.000000</td>\n      <td>0.077778</td>\n      <td>0.002222</td>\n      <td>1</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.773976</td>\n      <td>23.130514</td>\n      <td>0.000000</td>\n      <td>0.027826</td>\n      <td>0.000430</td>\n      <td>44</td>\n      <td>14.666667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.918308</td>\n      <td>13.351339</td>\n      <td>0.000000</td>\n      <td>0.014925</td>\n      <td>0.000104</td>\n      <td>22</td>\n      <td>7.333333</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.975355</td>\n      <td>18.240926</td>\n      <td>0.000000</td>\n      <td>0.053140</td>\n      <td>0.000255</td>\n      <td>8</td>\n      <td>2.666667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>273</td>\n      <td>79.670665</td>\n      <td>0.200000</td>\n      <td>0.990119</td>\n      <td>31.786048</td>\n      <td>0.333333</td>\n      <td>0.046512</td>\n      <td>0.000307</td>\n      <td>24</td>\n      <td>8.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 140 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc = drop(preproc, ['feature_20', 'feature_35'])\n",
    "preproc.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:49.926094100Z",
     "start_time": "2024-04-29T16:31:49.829270300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SCALING\n",
    "Заскейлим и сохраним результат\n",
    "\n",
    "для выбранных мной моделек скейлинг не нужен\n",
    "так что закомментил код"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "preproc = preproc.copy()\n",
    "# scaler =StandardScaler()\n",
    "#\n",
    "# to_scale = [i for i in preproc.columns.tolist() if i not in integer_columns and i not in bool_columns]\n",
    "#\n",
    "#\n",
    "# preproc[to_scale] = scaler.fit_transform(preproc[to_scale])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:50.082806400Z",
     "start_time": "2024-04-29T16:31:49.925593600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "        rank  query_id  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n0          0        10          1          0          1          3          3   \n1          1        10          3          0          3          0          3   \n2          0        10          3          0          2          0          3   \n3          1        10          3          0          3          0          3   \n4          2        10          3          0          3          1          3   \n...      ...       ...        ...        ...        ...        ...        ...   \n235253     2     29995          1          0          0          0          1   \n235254     2     29995          1          0          1          0          1   \n235255     1     29995          1          0          0          0          1   \n235256     2     29995          0          0          0          0          0   \n235257     1     29995          0          0          0          0          0   \n\n        feature_5  feature_6  feature_7  ...  feature_134  feature_135  \\\n0        0.333333        0.0   0.333333  ...            0     0.000000   \n1        1.000000        0.0   1.000000  ...            0     0.000000   \n2        1.000000        0.0   0.666667  ...            0     0.000000   \n3        1.000000        0.0   1.000000  ...            0     0.000000   \n4        1.000000        0.0   1.000000  ...          273    79.670665   \n...           ...        ...        ...  ...          ...          ...   \n235253   0.500000        0.0   0.000000  ...            0     0.000000   \n235254   0.500000        0.0   0.500000  ...            0     0.000000   \n235255   0.500000        0.0   0.000000  ...            0     0.000000   \n235256   0.000000        0.0   0.000000  ...            0     0.000000   \n235257   0.000000        0.0   0.000000  ...            0     0.000000   \n\n        feature_136  feature_137  feature_138  feature_139  feature_140  \\\n0          0.454545     0.890238     8.655534     1.000000     0.077778   \n1          0.000000     0.773976    23.130514     0.000000     0.027826   \n2          0.000000     0.918308    13.351339     0.000000     0.014925   \n3          0.000000     0.975355    18.240926     0.000000     0.053140   \n4          0.200000     0.990119    31.786048     0.333333     0.046512   \n...             ...          ...          ...          ...          ...   \n235253     0.000000     0.471409     0.000000     0.000000     0.001350   \n235254     0.000000     0.471409    39.908056     0.000000     0.004850   \n235255     0.000000     0.471409     0.000000     0.000000     0.001064   \n235256     0.000000     0.000000     0.000000     0.000000     0.000000   \n235257     0.000000     0.000000     0.000000     0.000000     0.000000   \n\n        feature_141  feature_142  feature_143  \n0          0.002222            1     0.333333  \n1          0.000430           44    14.666667  \n2          0.000104           22     7.333333  \n3          0.000255            8     2.666667  \n4          0.000307           24     8.000000  \n...             ...          ...          ...  \n235253     0.000002            3     1.500000  \n235254     0.000014            9     4.500000  \n235255     0.000001            1     0.500000  \n235256     0.000000            0     0.000000  \n235257     0.000000            0     0.000000  \n\n[235258 rows x 140 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank</th>\n      <th>query_id</th>\n      <th>feature_0</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>...</th>\n      <th>feature_134</th>\n      <th>feature_135</th>\n      <th>feature_136</th>\n      <th>feature_137</th>\n      <th>feature_138</th>\n      <th>feature_139</th>\n      <th>feature_140</th>\n      <th>feature_141</th>\n      <th>feature_142</th>\n      <th>feature_143</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>10</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.454545</td>\n      <td>0.890238</td>\n      <td>8.655534</td>\n      <td>1.000000</td>\n      <td>0.077778</td>\n      <td>0.002222</td>\n      <td>1</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.773976</td>\n      <td>23.130514</td>\n      <td>0.000000</td>\n      <td>0.027826</td>\n      <td>0.000430</td>\n      <td>44</td>\n      <td>14.666667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.918308</td>\n      <td>13.351339</td>\n      <td>0.000000</td>\n      <td>0.014925</td>\n      <td>0.000104</td>\n      <td>22</td>\n      <td>7.333333</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.975355</td>\n      <td>18.240926</td>\n      <td>0.000000</td>\n      <td>0.053140</td>\n      <td>0.000255</td>\n      <td>8</td>\n      <td>2.666667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>273</td>\n      <td>79.670665</td>\n      <td>0.200000</td>\n      <td>0.990119</td>\n      <td>31.786048</td>\n      <td>0.333333</td>\n      <td>0.046512</td>\n      <td>0.000307</td>\n      <td>24</td>\n      <td>8.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>235253</th>\n      <td>2</td>\n      <td>29995</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.471409</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.001350</td>\n      <td>0.000002</td>\n      <td>3</td>\n      <td>1.500000</td>\n    </tr>\n    <tr>\n      <th>235254</th>\n      <td>2</td>\n      <td>29995</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.500000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.471409</td>\n      <td>39.908056</td>\n      <td>0.000000</td>\n      <td>0.004850</td>\n      <td>0.000014</td>\n      <td>9</td>\n      <td>4.500000</td>\n    </tr>\n    <tr>\n      <th>235255</th>\n      <td>1</td>\n      <td>29995</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.471409</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.001064</td>\n      <td>0.000001</td>\n      <td>1</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>235256</th>\n      <td>2</td>\n      <td>29995</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>235257</th>\n      <td>1</td>\n      <td>29995</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>235258 rows × 140 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.to_csv('data/preproc.csv')\n",
    "preproc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:57.529748300Z",
     "start_time": "2024-04-29T16:31:50.070290300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проверим одну вещь: насколько у нас равномерно распределены ранги"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:28:02.736252500Z",
     "start_time": "2024-04-29T16:28:01.206139Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "preproc['rank'].value_counts().plot(kind='bar')\n",
    "plt.title('Target')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:57.589546400Z",
     "start_time": "2024-04-29T16:31:57.468176Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SPLIT\n",
    "\n",
    "разобьем модели на обучающую и валидирующие выборки\n",
    "на валидирующей будем замерять итоговую производительность модели"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:28:04.615672400Z",
     "start_time": "2024-04-29T16:28:04.304127400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 58,  84, 163, ..., 100,  71,  70], dtype=int64)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "gss = GroupShuffleSplit(test_size=.40, random_state=seed).split(preproc, groups=preproc['query_id'])\n",
    "\n",
    "X_train_inds, X_val_inds = next(gss)\n",
    "\n",
    "train_data = preproc.iloc[X_train_inds]\n",
    "X_train = train_data.loc[:, ~train_data.columns.isin(['rank'])]\n",
    "y_train = train_data.loc[:, train_data.columns.isin(['rank'])]\n",
    "\n",
    "groups = train_data.groupby('query_id').size().to_frame('size')['size'].to_numpy()\n",
    "\n",
    "groups"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:57.637855500Z",
     "start_time": "2024-04-29T16:31:57.551022200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "val_data = preproc.iloc[X_val_inds]\n",
    "\n",
    "X_val = val_data.loc[:, ~val_data.columns.isin(['rank'])]\n",
    "\n",
    "y_val = val_data.loc[:, val_data.columns.isin(['rank'])]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:57.659153300Z",
     "start_time": "2024-04-29T16:31:57.619850500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MODELS\n",
    "\n",
    "первой моделью будет классификатор на градиентном бустинге, но т.к. у нас дизбаланс по целевой переменной, то мы будем обучать с весами"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=y_train\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:31:57.674543700Z",
     "start_time": "2024-04-29T16:31:57.659653300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.9, device='cuda', early_stopping_rounds=None,\n              enable_categorical=False, eta=0.05, eval_metric=None,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=3000,\n              n_jobs=None, num_parallel_tree=None, ...)",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.9, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n              enable_categorical=False, eta=0.05, eval_metric=None,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=3000,\n              n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.9, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n              enable_categorical=False, eta=0.05, eval_metric=None,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=3000,\n              n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelClassifier = xgb.XGBClassifier(\n",
    "    tree_method='hist',\n",
    "    device='cuda',\n",
    "    booster='gbtree',\n",
    "    random_state=42,\n",
    "    learning_rate=0.1,\n",
    "    colsample_bytree=0.9,\n",
    "    eta=0.05,\n",
    "    max_depth=10,\n",
    "    n_estimators=3000,\n",
    "    subsample=0.75\n",
    ")\n",
    "\n",
    "modelClassifier.fit(X_train, y_train, verbose=True, sample_weight=classes_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:34:18.524124500Z",
     "start_time": "2024-04-29T16:31:57.673539400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Предскажем значения"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python311\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [19:34:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "query_id\n10     [0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, ...\n55     [0, 2, 0, 2, 0, 0, 0, 1, 2, 0, 0, 1, 0, 2, 0, ...\n100    [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 2, 0, ...\n175    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n220    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\ndtype: object"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsClassifier = X_val.groupby('query_id').apply(lambda x: modelClassifier.predict(x))\n",
    "predictionsClassifier.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:38:41.802825Z",
     "start_time": "2024-04-29T16:34:18.524624200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Но это кажется немного странным решать проблему ранжирования классификатором, так что давайте обучим ранкер"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBRanker(base_score=None, booster='gbtree', callbacks=None,\n          colsample_bylevel=None, colsample_bynode=None, colsample_bytree=0.9,\n          device='cuda', early_stopping_rounds=None, enable_categorical=False,\n          eta=0.05, eval_metric=None, feature_types=None, gamma=None,\n          grow_policy=None, importance_type=None, interaction_constraints=None,\n          lambdarank_num_pair_per_sample=20, lambdarank_pair_method='topk',\n          learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n          max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n          max_leaves=None, min_child_weight=None, missing=nan,\n          monotone_constraints=None, multi_strategy=None, n_estimators=3000, ...)",
      "text/html": "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRanker(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n          colsample_bylevel=None, colsample_bynode=None, colsample_bytree=0.9,\n          device=&#x27;cuda&#x27;, early_stopping_rounds=None, enable_categorical=False,\n          eta=0.05, eval_metric=None, feature_types=None, gamma=None,\n          grow_policy=None, importance_type=None, interaction_constraints=None,\n          lambdarank_num_pair_per_sample=20, lambdarank_pair_method=&#x27;topk&#x27;,\n          learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n          max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n          max_leaves=None, min_child_weight=None, missing=nan,\n          monotone_constraints=None, multi_strategy=None, n_estimators=3000, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRanker</label><div class=\"sk-toggleable__content\"><pre>XGBRanker(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n          colsample_bylevel=None, colsample_bynode=None, colsample_bytree=0.9,\n          device=&#x27;cuda&#x27;, early_stopping_rounds=None, enable_categorical=False,\n          eta=0.05, eval_metric=None, feature_types=None, gamma=None,\n          grow_policy=None, importance_type=None, interaction_constraints=None,\n          lambdarank_num_pair_per_sample=20, lambdarank_pair_method=&#x27;topk&#x27;,\n          learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n          max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n          max_leaves=None, min_child_weight=None, missing=nan,\n          monotone_constraints=None, multi_strategy=None, n_estimators=3000, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRanker = xgb.XGBRanker(\n",
    "    tree_method='hist',\n",
    "    device='cuda',\n",
    "    booster='gbtree',\n",
    "    random_state=42,\n",
    "    learning_rate=0.1,\n",
    "    colsample_bytree=0.9,\n",
    "    eta=0.05,\n",
    "    max_depth=10,\n",
    "    n_estimators=3000,\n",
    "    subsample=0.75,\n",
    "    objective=\"rank:ndcg\",\n",
    "    lambdarank_pair_method=\"topk\",\n",
    "    lambdarank_num_pair_per_sample=20,\n",
    ")\n",
    "\n",
    "modelRanker.fit(X_train, y_train, group=groups, verbose=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:39:13.310376700Z",
     "start_time": "2024-04-29T16:38:41.803828200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "query_id\n10     [-4.174199, -0.90505755, -6.2074065, -1.650884...\n55     [-6.984021, -2.6642802, -4.743905, -3.61525, -...\n100    [-2.704109, -2.7523136, -4.84955, -3.375681, -...\n175    [-4.789821, -2.8087776, -4.00264, -4.4328184, ...\n220    [-8.767288, -6.472885, -6.0132356, -5.5641737,...\ndtype: object"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsRanker = X_val.groupby('query_id').apply(lambda x: modelRanker.predict(x))\n",
    "predictionsRanker.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:40:12.139853900Z",
     "start_time": "2024-04-29T16:39:13.310376700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "А вот тут давайте возьмем что-то интереснее и воспользуемся модным AutoML, правда в знакомых мне библиотеках нет специального сценария для работы с задачей ранжирования, но autogluon пишут, что работают над этим и когда-то добавят такой функционал"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240428_204248\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 3600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20240428_204248/ds_sub_fit/sub_fit_ho.\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240428_204248/ds_sub_fit/sub_fit_ho\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Jan 11 04:09:03 UTC 2024\n",
      "CPU Count:          32\n",
      "Memory Avail:       12.07 GB / 15.51 GB (77.8%)\n",
      "Disk Space Avail:   40.20 GB / 930.79 GB (4.3%)\n",
      "===================================================\n",
      "Train Data Rows:    126153\n",
      "Train Data Columns: 139\n",
      "Label Column:       rank\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12229.85 MB\n",
      "\tTrain Data (Original)  Memory Usage: 129.57 MB (1.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  :  5 | ['feature_95', 'feature_96', 'feature_97', 'feature_98', 'feature_99']\n",
      "\t\t('float', []) : 98 | ['feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', ...]\n",
      "\t\t('int', [])   : 36 | ['query_id', 'feature_0', 'feature_1', 'feature_2', 'feature_3', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 98 | ['feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', ...]\n",
      "\t\t('int', [])       : 36 | ['query_id', 'feature_0', 'feature_1', 'feature_2', 'feature_3', ...]\n",
      "\t\t('int', ['bool']) :  5 | ['feature_95', 'feature_96', 'feature_97', 'feature_98', 'feature_99']\n",
      "\t0.6s = Fit runtime\n",
      "\t139 features in original data used to generate 139 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 129.57 MB (1.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.74s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 599.35s of the 899.25s of remaining time.\n",
      "\t0.4569\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t14.96s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 583.52s of the 883.42s of remaining time.\n",
      "\t0.4643\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t14.7s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 567.99s of the 867.89s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.86% memory usage per fold, 47.46%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.86%)\n",
      "\t0.5442\t = Validation score   (f1_weighted)\n",
      "\t452.56s\t = Training   runtime\n",
      "\t0.96s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 111.59s of the 411.48s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 13.04% memory usage per fold, 52.14%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=13.04%)\n",
      "\t0.4575\t = Validation score   (f1_weighted)\n",
      "\t60.44s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 49.86s of the 349.76s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.56% memory usage per fold, 42.25%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=10.56%)\n",
      "\t0.4489\t = Validation score   (f1_weighted)\n",
      "\t47.43s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1.25s of the 301.15s of remaining time.\n",
      "\tWarning: Model is expected to require 51.1s to train, which exceeds the maximum time limit of 1.3s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 0.14s of the 300.04s of remaining time.\n",
      "\tWarning: Model is expected to require 64.6s to train, which exceeds the maximum time limit of 0.1s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestEntr_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 297.73s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.929, 'KNeighborsDist_BAG_L1': 0.071}\n",
      "\t0.5448\t = Validation score   (f1_weighted)\n",
      "\t11.97s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 285.68s of the 285.53s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 17.53% memory usage per fold, 70.12%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=17.53%)\n",
      "\t0.5494\t = Validation score   (f1_weighted)\n",
      "\t229.7s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 54.63s of the 54.52s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 15.12% memory usage per fold, 60.49%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=15.12%)\n",
      "\t0.4617\t = Validation score   (f1_weighted)\n",
      "\t50.86s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 1.09s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.857, 'NeuralNetFastAI_BAG_L1': 0.143}\n",
      "\t0.5501\t = Validation score   (f1_weighted)\n",
      "\t16.05s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 915.44s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240428_204248/ds_sub_fit/sub_fit_ho\")\n",
      "Leaderboard on holdout data from dynamic stacking:\n",
      "                    model  holdout_score  score_val  eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     WeightedEnsemble_L3       0.549332   0.550090  f1_weighted        8.170526      32.573735  806.849522                 0.005867                0.020764          16.047984            3       True          9\n",
      "1  NeuralNetFastAI_BAG_L2       0.548850   0.549359  f1_weighted        8.164659      32.552971  790.801538                 0.980661                0.981111         229.701199            2       True          7\n",
      "2     WeightedEnsemble_L2       0.545355   0.544795  f1_weighted        4.189284      15.686486  464.869487                 0.007655                0.020609          11.973573            2       True          6\n",
      "3  NeuralNetFastAI_BAG_L1       0.543840   0.544212  f1_weighted        1.614638       0.961333  452.564400                 1.614638                0.961333         452.564400            1       True          3\n",
      "4   KNeighborsDist_BAG_L1       0.469853   0.464291  f1_weighted        2.566992      14.704545    0.331513                 2.566992               14.704545           0.331513            1       True          2\n",
      "5   KNeighborsUnif_BAG_L1       0.460170   0.456886  f1_weighted        2.675659      14.963920    0.329376                 2.675659               14.963920           0.329376            1       True          1\n",
      "6         LightGBM_BAG_L1       0.426295   0.448924  f1_weighted        0.162695       0.410052   47.433024                 0.162695                0.410052          47.433024            1       True          5\n",
      "7       LightGBMXT_BAG_L2       0.425654   0.461725  f1_weighted        7.358965      31.943309  611.963207                 0.174967                0.371450          50.862868            2       True          8\n",
      "8       LightGBMXT_BAG_L1       0.423532   0.457525  f1_weighted        0.164014       0.532010   60.442025                 0.164014                0.532010          60.442025            1       True          4\n",
      "Stacked overfitting occurred: False.\n",
      "Spend 924 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 2676 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 2676s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240428_204248\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Jan 11 04:09:03 UTC 2024\n",
      "CPU Count:          32\n",
      "Memory Avail:       8.60 GB / 15.51 GB (55.4%)\n",
      "Disk Space Avail:   40.19 GB / 930.79 GB (4.3%)\n",
      "===================================================\n",
      "Train Data Rows:    141923\n",
      "Train Data Columns: 139\n",
      "Label Column:       rank\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8673.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 145.77 MB (1.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  :  5 | ['feature_95', 'feature_96', 'feature_97', 'feature_98', 'feature_99']\n",
      "\t\t('float', []) : 98 | ['feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', ...]\n",
      "\t\t('int', [])   : 36 | ['query_id', 'feature_0', 'feature_1', 'feature_2', 'feature_3', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 98 | ['feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', ...]\n",
      "\t\t('int', [])       : 36 | ['query_id', 'feature_0', 'feature_1', 'feature_2', 'feature_3', ...]\n",
      "\t\t('int', ['bool']) :  5 | ['feature_95', 'feature_96', 'feature_97', 'feature_98', 'feature_99']\n",
      "\t0.7s = Fit runtime\n",
      "\t139 features in original data used to generate 139 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 145.77 MB (1.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.83s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1783.0s of the 2675.16s of remaining time.\n",
      "\t0.4585\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t19.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1762.8s of the 2654.97s of remaining time.\n",
      "\t0.4668\t = Validation score   (f1_weighted)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t19.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1742.83s of the 2634.99s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.62% memory usage per fold, 74.47%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=18.62%)\n",
      "\t0.546\t = Validation score   (f1_weighted)\n",
      "\t664.67s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1076.86s of the 1969.02s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 15.65% memory usage per fold, 62.59%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=15.65%)\n",
      "\t0.4394\t = Validation score   (f1_weighted)\n",
      "\t119.27s\t = Training   runtime\n",
      "\t2.75s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 956.42s of the 1848.58s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.28% memory usage per fold, 49.12%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=12.28%)\n",
      "\t0.4597\t = Validation score   (f1_weighted)\n",
      "\t79.55s\t = Training   runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 875.73s of the 1767.9s of remaining time.\n",
      "\t0.5662\t = Validation score   (f1_weighted)\n",
      "\t11.93s\t = Training   runtime\n",
      "\t5.39s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 853.11s of the 1745.28s of remaining time.\n",
      "\t0.5664\t = Validation score   (f1_weighted)\n",
      "\t14.23s\t = Training   runtime\n",
      "\t5.34s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 819.89s of the 1712.06s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.89% memory usage per fold, 59.58%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=14.89%)\n",
      "\t0.5262\t = Validation score   (f1_weighted)\n",
      "\t53.09s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 765.64s of the 1657.8s of remaining time.\n",
      "\t0.5485\t = Validation score   (f1_weighted)\n",
      "\t4.02s\t = Training   runtime\n",
      "\t5.25s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 751.66s of the 1643.83s of remaining time.\n",
      "\t0.5483\t = Validation score   (f1_weighted)\n",
      "\t3.76s\t = Training   runtime\n",
      "\t5.19s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 735.27s of the 1627.44s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.91% memory usage per fold, 75.64%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=18.91%)\n",
      "\t0.5767\t = Validation score   (f1_weighted)\n",
      "\t402.99s\t = Training   runtime\n",
      "\t2.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 330.75s of the 1222.91s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.84% memory usage per fold, 47.37%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.84%)\n",
      "\t0.5401\t = Validation score   (f1_weighted)\n",
      "\t274.61s\t = Training   runtime\n",
      "\t1.64s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 54.8s of the 946.96s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 21.10% memory usage per fold, 42.20%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=21.10%)\n",
      "\t0.3933\t = Validation score   (f1_weighted)\n",
      "\t52.12s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1.38s of the 893.54s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 15.03% memory usage per fold, 60.14%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=15.03%)\n",
      "2024-04-29 00:28:02,462\tERROR serialization.py:389 -- Failed to unpickle serialized exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/exceptions.py\", line 46, in from_ray_exception\n",
      "    return pickle.loads(ray_exception.serialized_exception)\n",
      "ModuleNotFoundError: No module named '_catboost'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/_private/serialization.py\", line 387, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/_private/serialization.py\", line 291, in _deserialize_object\n",
      "    return RayError.from_bytes(obj)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/exceptions.py\", line 40, in from_bytes\n",
      "    return RayError.from_ray_exception(ray_exception)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/exceptions.py\", line 49, in from_ray_exception\n",
      "    raise RuntimeError(msg) from e\n",
      "RuntimeError: Failed to unpickle serialized exception\n",
      "\tWarning: Exception caused CatBoost_r177_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tSystem error: Failed to unpickle serialized exception\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/exceptions.py\", line 46, in from_ray_exception\n",
      "    return pickle.loads(ray_exception.serialized_exception)\n",
      "ModuleNotFoundError: No module named '_catboost'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/_private/serialization.py\", line 387, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/_private/serialization.py\", line 291, in _deserialize_object\n",
      "    return RayError.from_bytes(obj)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/exceptions.py\", line 40, in from_bytes\n",
      "    return RayError.from_ray_exception(ray_exception)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/exceptions.py\", line 49, in from_ray_exception\n",
      "    raise RuntimeError(msg) from e\n",
      "RuntimeError: Failed to unpickle serialized exception\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 273, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 689, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 661, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 603, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 566, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 532, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/_private/worker.py\", line 2526, in get\n",
      "    raise value\n",
      "ray.exceptions.RaySystemError: System error: Failed to unpickle serialized exception\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/exceptions.py\", line 46, in from_ray_exception\n",
      "    return pickle.loads(ray_exception.serialized_exception)\n",
      "ModuleNotFoundError: No module named '_catboost'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/_private/serialization.py\", line 387, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/_private/serialization.py\", line 291, in _deserialize_object\n",
      "    return RayError.from_bytes(obj)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/exceptions.py\", line 40, in from_bytes\n",
      "    return RayError.from_ray_exception(ray_exception)\n",
      "  File \"/home/chipch1n/.local/lib/python3.10/site-packages/ray/exceptions.py\", line 49, in from_ray_exception\n",
      "    raise RuntimeError(msg) from e\n",
      "RuntimeError: Failed to unpickle serialized exception\n",
      "\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 886.02s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 1.0}\n",
      "\t0.5767\t = Validation score   (f1_weighted)\n",
      "\t32.09s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 853.86s of the 853.57s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 27.88% memory usage per fold, 55.76%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=27.88%)\n",
      "\t0.5931\t = Validation score   (f1_weighted)\n",
      "\t645.2s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 207.05s of the 206.8s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 19.22% memory usage per fold, 76.86%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=19.22%)\n",
      "\t0.5189\t = Validation score   (f1_weighted)\n",
      "\t107.76s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 97.88s of the 97.63s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 19.85% memory usage per fold, 79.38%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=19.85%)\n",
      "\t0.5345\t = Validation score   (f1_weighted)\n",
      "\t81.96s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 14.43s of the 14.19s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 41 due to low time. Expected time usage reduced from 104.2s -> 14.4s...\n",
      "\t0.5694\t = Validation score   (f1_weighted)\n",
      "\t5.18s\t = Training   runtime\n",
      "\t1.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 5.22s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.913, 'RandomForestGini_BAG_L1': 0.043, 'RandomForestGini_BAG_L2': 0.043}\n",
      "\t0.5936\t = Validation score   (f1_weighted)\n",
      "\t41.22s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2712.55s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240428_204248\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor, TabularDataset\n",
    "\n",
    "predictor = TabularPredictor(label='rank', eval_metric='f1_weighted').fit(\n",
    "    train_data=TabularDataset(train_data),\n",
    "    presets='best_quality',\n",
    "    ag_args_fit={'num_gpus': 1},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T21:43:25.705637700Z",
     "start_time": "2024-04-28T20:42:48.685524700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Предсказания такой моделью занимают вечность, поэтому я получил предсказания один раз и сохранил их"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "query_id\n10                                    [0, 1, 0, 0, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n55                                                                                                                                          [0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 2, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 2, 2, 1, 1, 1, 2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n100                                               [1, 1, 0, 1, 0, 0, 0, 1, 1, 2, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 2, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n175                                                                                                                                                                                                        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n220      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n                                                                                                                                                               ...                                                                                                                                                        \n29815                                                                                                                        [0, 0, 1, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 2, 1, 0, 0, 1, 2, 1, 1, 2, 0, 1, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0]\n29860    [0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 2, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 2, 1, 0, 2, 2, 1, 1, 0, 1, 1, 1, 0, 0, ...]\n29890    [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...]\n29920                                                                                                [2, 1, 0, 1, 0, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 0, 2, 2, 2, 2, 0, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 0, 1, 2, 1, 0, 2, 1, 2, 2, 2, 0, 0, 1, 2, 0, 0, 2, 2]\n29995                                                                  [0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]\nLength: 800, dtype: object"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsAutoML = X_val.groupby('query_id').apply(lambda x: predictor.predict(x).to_numpy())\n",
    "predictionsAutoML"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T12:26:44.681786200Z",
     "start_time": "2024-04-29T12:26:44.660772100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "predictionsAutoML.to_csv('automlrecs.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T00:45:36.568923Z",
     "start_time": "2024-04-29T00:45:36.533412600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictionsAutoML = pd.read_csv('automlrecs.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RESULTS\n",
    "\n",
    "Самое интересное, давайте посмотрим и сравним эффективность полученных моделек\n",
    "\n",
    "Соберем датафрейм с правильным ранжированием"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "query_id\n10                                  [0, 1, 0, 1, 2, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 2, 4, 0, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 2, 0, 0, 1, 2, 1, 1, 2, 0, 1, 0, 1, 2, 0, 0, 1, 0, 0, 3, 2, 1, 1, 0, 0, 1, 2, 0, 2, 0, 0, 0, 0, 4, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0, 1, 1, 0, 1, 1, 0]\n55                                                                                                                                        [1, 2, 0, 2, 1, 0, 2, 2, 3, 0, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 3, 1, 1, 2, 0, 0, 1, 0, 1, 2, 0, 1, 0, 1, 1, 1, 1, 0, 0, 2, 1, 1, 1, 2, 0, 0, 1, 2, 0, 0, 2, 4, 2, 1, 0, 0]\n100                                             [1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 0, 4, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 0, 0, 1, 3, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n175                                                                                                                                                                                                      [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]\n220    [0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 1, 0, 0, 0, 2, 1, 1, 1, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, ...]\ndtype: object"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = X_val.groupby('query_id').apply(lambda x: [y_val.loc[i]['rank'] for i in x.index])\n",
    "y_true.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:04:32.019941500Z",
     "start_time": "2024-04-29T08:04:30.334843300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Введём метрики оценки:\n",
    "\n",
    "ndcg@5\n",
    "ndcg@20\n",
    "ndcg\n",
    "precision@5\n",
    "precision@20\n",
    "precision\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "\n",
    "def ndcg(k=None):\n",
    "    return lambda y_true, y_pred: ndcg_score([y_true], [y_pred], k=k)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "def precision_at_k(k=None):\n",
    "    return lambda y_true, y_pred: precision_at_k_func(y_true, y_pred, k=k)\n",
    "\n",
    "\n",
    "def precision_at_k_func(y_true, y_pred, k=None):\n",
    "    if k and len(y_pred) > k:\n",
    "        y_pred = y_pred[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(y_pred):\n",
    "        if p in y_true and p not in y_pred[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "\n",
    "    if not y_true:\n",
    "        return 0.0\n",
    "    if k:\n",
    "        return score / min(len(y_true), k)\n",
    "    return score / len(y_true)\n",
    "\n",
    "\n",
    "def score(y_true, y_predictions, metric=precision_score):\n",
    "    res = []\n",
    "    for i, y_pred in enumerate(y_predictions):\n",
    "        if len(y_pred) > 1:\n",
    "            res.append(metric(y_true.iloc[i], y_pred))\n",
    "    return sum(res) / len(res)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T15:31:52.420203Z",
     "start_time": "2024-04-29T15:31:52.380173500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Т.к. ранкер выдает свой скоринг, то для подсчета precision надо сделать перевод в оценки от 0 до 4, сделаем это таким наивным способом"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "query_id\n10                                    [2, 3, 1, 3, 4, 3, 2, 3, 1, 2, 2, 3, 2, 3, 3, 3, 3, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 0, 3, 3, 2, 3, 3, 2, 2, 2, 1, 2, 2, 1, 4, 2, 2, 3, 3, 3, 3, 3, 2, 1, 1, 3, 4, 2, 0, 2, 2, 2, 3, 3, 4, 2, 2, 1, 4, 2, 2, 3, 2, 2, 1, 1, 4, 3, 1, 1, 3, 2, 1, 1, 1, 1, 1, 2, 3, 2, 3, 3, 2, 2, 3, 2]\n55                                                                                                                                          [1, 3, 2, 3, 3, 4, 1, 2, 3, 1, 1, 2, 2, 3, 3, 4, 3, 2, 2, 3, 1, 4, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 1, 4, 1, 1, 1, 3, 4, 3, 3, 4, 4, 1, 2, 1, 0, 2, 1, 4, 1, 2, 1, 4, 2, 0, 0, 0]\n100                                               [3, 3, 2, 3, 2, 1, 3, 2, 2, 3, 2, 3, 2, 4, 2, 0, 3, 2, 3, 3, 1, 2, 2, 1, 2, 2, 3, 2, 3, 1, 3, 3, 1, 2, 4, 2, 3, 2, 4, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 1, 2, 1, 2, 3, 1, 1, 3, 2, 2, 2, 2, 2, 3, 1, 3, 3, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 1, 3, 3, 1, 3, 2, 3]\n175                                                                                                                                                                                                        [2, 3, 2, 2, 1, 2, 2, 2, 1, 3, 2, 1, 2, 1, 2, 2, 2, 2, 3, 1, 2, 0, 4, 3, 2, 2, 1, 1, 0, 2, 3, 2, 2, 3, 1, 1, 1]\n220      [1, 2, 2, 2, 3, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 4, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 3, 2, 2, 3, 3, 2, 4, 2, 2, 4, 2, 2, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 3, 1, 3, 2, 2, 1, 1, 3, 2, 2, 2, 2, 2, 2, 4, 2, 2, 3, 3, 2, 1, 3, 3, 2, 1, 2, 2, 3, 3, 2, 2, 3, 2, 3, 3, 2, 3, 2, 3, 3, 2, 2, 1, 2, ...]\n                                                                                                                                                               ...                                                                                                                                                        \n29815                                                                                                                        [1, 1, 1, 2, 0, 2, 2, 2, 3, 3, 1, 2, 2, 3, 1, 1, 2, 1, 4, 2, 2, 3, 2, 1, 2, 3, 2, 3, 3, 0, 1, 1, 4, 1, 2, 4, 2, 1, 0, 1, 3, 2, 0, 0, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 3, 2, 2, 0, 0]\n29860    [2, 2, 2, 2, 4, 3, 2, 2, 3, 3, 2, 3, 3, 3, 3, 2, 2, 2, 3, 2, 3, 2, 1, 1, 2, 2, 3, 2, 3, 3, 3, 2, 2, 2, 3, 2, 2, 3, 2, 3, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 3, 1, 3, 2, 2, 2, 0, 2, 2, 2, 3, 3, 2, 3, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 3, 0, 0, 3, 3, 2, 2, 4, 2, 2, 3, 4, 2, 3, 2, 2, 2, 3, 2, 2, ...]\n29890    [1, 1, 1, 2, 2, 2, 2, 2, 1, 3, 0, 2, 2, 1, 3, 1, 2, 4, 1, 1, 1, 3, 2, 2, 1, 2, 1, 0, 3, 1, 1, 2, 2, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 3, 1, 2, 3, 1, 1, 1, 2, 1, 2, 1, 1, 3, 2, 2, 2, 2, 1, 1, 4, 2, 0, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 3, 3, 1, 2, 3, 1, 1, 0, 3, 2, 2, 1, 0, 2, 3, 3, 3, 2, 2, 1, 1, ...]\n29920                                                                                                [3, 2, 1, 1, 1, 2, 2, 4, 2, 3, 2, 2, 1, 2, 2, 3, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 3, 2, 4, 2, 2, 3, 2, 3, 1, 2, 3, 2, 2, 2, 2, 4, 1, 2, 3, 2, 3, 3, 4, 2, 2, 3, 1, 2, 3, 1, 2, 3, 2, 2, 3, 2, 1, 0, 3, 3, 1, 1, 2, 2]\n29995                                                                  [1, 2, 3, 2, 3, 3, 2, 2, 3, 1, 2, 1, 2, 1, 1, 2, 2, 3, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 4, 3, 3, 1, 2, 1, 2, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 2, 3, 2, 4, 3, 2, 1, 3, 3, 1, 3, 2, 2, 3, 2, 1, 2, 1, 3, 0, 2, 1, 1, 3, 2, 2, 2, 3, 1, 3, 3, 2, 3, 1]\nLength: 800, dtype: object"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scale_and_transform(x, num_classes=5):\n",
    "    scaled_x = ((x - np.min(x)) / (np.max(x) - np.min(x))) * (num_classes - 1)\n",
    "\n",
    "    int_x = np.round(scaled_x).astype(int)\n",
    "\n",
    "    return int_x\n",
    "\n",
    "\n",
    "predictionsRankerScaled = predictionsRanker.copy()\n",
    "predictionsRankerScaled = predictionsRankerScaled.apply(scale_and_transform)\n",
    "predictionsRankerScaled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T15:31:52.980876400Z",
     "start_time": "2024-04-29T15:31:52.882306600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "def get_scores(y_true, y_pred):\n",
    "    res = dict()\n",
    "    res['ndcg@5'] = score(y_true, y_pred, ndcg(k=5))\n",
    "    res['ndcg@20'] = score(y_true, y_pred, ndcg(k=20))\n",
    "    res['ndcg'] = score(y_true, y_pred, ndcg())\n",
    "    res['precision@5'] = score(y_true, y_pred, precision_at_k(5))\n",
    "    res['precision@20'] = score(y_true, y_pred, precision_at_k(20))\n",
    "    res['precision'] = score(y_true, y_pred, precision_at_k())\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T15:31:54.034713800Z",
     "start_time": "2024-04-29T15:31:54.029209Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier\n",
      "{'ndcg@5': 0.4224788090374609, 'ndcg@20': 0.45829025689136466, 'ndcg': 0.7057453846301025, 'precision@5': 0.3199249061326662, 'precision@20': 0.09100049966549843, 'precision': 0.02438493179620645}\n",
      "Ranker\n",
      "{'ndcg@5': 0.5271884043511587, 'ndcg@20': 0.5455631143262684, 'ndcg': 0.7527911709216404, 'precision@5': 0.0, 'precision@20': 0.0, 'precision': 0.0}\n",
      "RankerScaled\n",
      "{'ndcg@5': 0.49751929527160754, 'ndcg@20': 0.5173012724732965, 'ndcg': 0.7398074185543564, 'precision@5': 0.3553045473508561, 'precision@20': 0.10670884700431965, 'precision': 0.026698199223644095}\n",
      "AutoML\n",
      "{'ndcg@5': 0.4465445275130479, 'ndcg@20': 0.47250844759105026, 'ndcg': 0.7135340377947786, 'precision@5': 0.31168961201501955, 'precision@20': 0.08743536155268668, 'precision': 0.023375293556066983}\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier\")\n",
    "print(get_scores(y_true, predictionsClassifier))\n",
    "\n",
    "print(\"Ranker\")\n",
    "print(get_scores(y_true, predictionsRanker))\n",
    "\n",
    "print(\"RankerScaled\")\n",
    "print(get_scores(y_true, predictionsRankerScaled))\n",
    "\n",
    "print(\"AutoML\")\n",
    "print(get_scores(y_true, predictionsAutoML))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T15:32:09.210972500Z",
     "start_time": "2024-04-29T15:31:55.708495900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Лучшего всего себя показал XGBRAnker"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
